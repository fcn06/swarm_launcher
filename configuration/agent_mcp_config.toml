#################################################################
# Config for MCP Runtime Agent
#################################################################

#################################################################
# General parameters
#################################################################
agent_mcp_role_tool = "tool"
agent_mcp_system_prompt= "You are a helpful assistant that answers user requests. You can use one or more tools. When you receive a message with a role called \"tool\", you must use the response from tools in order to build a final answer."
agent_mcp_role_assistant = "assistant"
agent_mcp_tool_choice_auto = "auto"
agent_mcp_finish_reason_tool_calls = "tool_calls"
agent_mcp_finish_reason_stop = "stop"
# max number of loops that the agent will execute
agent_mcp_max_loops = 5

#################################################################
# Parameters of the MCP middleware to connect to
# You can define an API Key here to connect to this mcp server
#################################################################
agent_mcp_server_url="http://localhost:8000/sse"
agent_mcp_server_api_key="<YOUR_API_KEY>"

#################################################################
# Define her the url of openai compatible endpoint 
# as well as the model to use
#################################################################
#agent_mcp_model_id="qwen/qwen3-32b"
#agent_mcp_llm_url="https://api.groq.com/openai/v1/chat/completions"
agent_mcp_model_id="gemini-2.0-flash"
agent_mcp_llm_url ="https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"

#################################################################
# In case you want to launch a rest endpoint to interact 
# with mcp runtime agent, here is the url
#################################################################
agent_mcp_endpoint="http://localhost:3000/"
